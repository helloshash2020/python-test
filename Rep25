import schedule
import time
import psycopg2
import pandas as pd
from openpyxl import Workbook
import datetime
import socket
import logging
import requests
import os

# Configure logging
logging.basicConfig(filename='query_log.txt', level=logging.INFO,
                    format='%(asctime)s - %(levelname)s: %(message)s')

# PostgreSQL connection parameters
db_params = {
    'dbname': 'your_database_name',
    'user': 'your_username',
    'password': 'your_password',
    'host': 'your_database_host',
    'port': 'your_database_port'
}

# Define your SQL queries
queries = [
    {
        'name': 'query_1',
        'sql': 'SELECT * FROM your_table_1'
    },
    {
        'name': 'query_2',
        'sql': 'SELECT * FROM your_table_2'
    }
]

# Confluence credentials
confluence_username = 'your_confluence_username'
confluence_password = 'your_confluence_password'
confluence_page_id = 'your_confluence_page_id'

def run_queries_and_generate_report():
    current_datetime = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    host_name = socket.gethostname()
    output_directory = 'query_outputs'
    
    # Create a directory for query outputs if it doesn't exist
    if not os.path.exists(output_directory):
        os.makedirs(output_directory)

    try:
        # Connect to the PostgreSQL database
        conn = psycopg2.connect(**db_params)

        for query in queries:
            cursor = conn.cursor()
            cursor.execute(query['sql'])
            query_result = cursor.fetchall()
            cursor.close()

            # Create a Pandas DataFrame from the query result
            df_query = pd.DataFrame(query_result, columns=[desc[0] for desc in cursor.description])

            # Remove timezone from datetime columns
            datetime_columns = [col for col in df_query.columns if df_query[col].dtype == 'datetime64[ns, UTC]']
            df_query[datetime_columns] = df_query[datetime_columns].apply(lambda x: x.dt.tz_localize(None))

            # Create an Excel file for each query output
            query_output_file = f'{query["name"]}_{current_datetime}.xlsx'
            df_query.to_excel(os.path.join(output_directory, query_output_file), index=False)

        # Log success
        logging.info(f'Reports generated at {current_datetime} on host {host_name}')

        # Upload the generated Excel files to Confluence
        for query in queries:
            query_output_file = f'{query["name"]}_{current_datetime}.xlsx'
            confluence_url = f'https://your-confluence-site/rest/api/content/{confluence_page_id}/child/{query_output_file}'
            headers = {"X-Atlassian-Token": "no-check"}
            files = {"file": (query_output_file, open(os.path.join(output_directory, query_output_file), "rb"))}
            auth = (confluence_username, confluence_password)

            response = requests.post(confluence_url, headers=headers, files=files, auth=auth)
            if response.status_code == 200:
                logging.info(f'Uploaded {query_output_file} to Confluence successfully!')
            else:
                logging.error(f'Failed to upload {query_output_file} to Confluence.')

    except Exception as e:
        logging.error(f'Error: {str(e)}')

    finally:
        # Remove old Excel files
        for query in queries:
            old_files = os.listdir(output_directory)
            for file in old_files:
                if file.startswith(f'{query["name"]}_') and not file.endswith(f'{current_datetime}.xlsx'):
                    os.remove(os.path.join(output_directory, file))

# Schedule the task to run every 2 minutes
schedule.every(2).minutes.do(run_queries_and_generate_report)

# Infinite loop to keep the script running
while True:
    schedule.run_pending()
    time.sleep(1)

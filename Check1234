import os
import schedule
import time
import datetime
import socket
import psycopg2
import requests
import csv
import logging

# Configure logging
logging.basicConfig(
    filename="postgres_data_collection.log",
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)

# Set your PostgreSQL connection parameters
db_params = {
    "host": "your_postgres_host",
    "database": "your_database",
    "user": "your_user",
    "password": "your_password",
}

# Set the Confluence API endpoint and credentials
confluence_api_url = "https://your-confluence-site/rest/api/content/YOUR_PAGE_ID"  # Update with your Confluence page URL
confluence_username = "your_username"
confluence_password = "your_password"

# Directory to store data files
data_directory = "data"

# Initialize data lists
all_slot_data = []
all_stat_data = []

# Function to fetch data from PostgreSQL and write it to CSV files
def fetch_and_write_to_csv(query, filename, data_list):
    try:
        connection = psycopg2.connect(**db_params)
        cursor = connection.cursor()

        # Execute the query
        cursor.execute(query)
        result = cursor.fetchall()

        # Append data to the data list
        data_list.extend(result)

        # Write data to the CSV file
        with open(filename, mode='a', newline='') as file:
            writer = csv.writer(file)
            if os.path.getsize(filename) == 0:
                # Write headers only if the file is empty
                header = ["Timestamp", "Hostname"] + [desc[0] for desc in cursor.description]
                writer.writerow(header)
            timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            hostname = socket.gethostname()
            for row in result:
                # Convert the row data (tuple) to a list and concatenate
                data = [timestamp, hostname] + list(map(str, row))  # Convert all elements to strings
                writer.writerow(data)
    except Exception as e:
        logging.error(f"Error fetching data and writing to CSV: {str(e)}")
    finally:
        if connection:
            connection.close()

# Function to post a file as an attachment to Confluence
def post_to_confluence(filename):
    auth = (confluence_username, confluence_password)

    # Get the current Confluence page ID from the URL
    confluence_page_id = confluence_api_url.split("/")[-1]

    # Define the URL for uploading an attachment to the Confluence page
    upload_url = f"https://your-confluence-site/rest/api/content/{confluence_page_id}/child/attachment"

    # Set the headers for the attachment
    headers = {
        "X-Atlassian-Token": "nocheck",  # Disable CSRF token
    }

    with open(filename, "rb") as file:
        # Create a new attachment on the Confluence page
        response = requests.post(upload_url, auth=auth, headers=headers, files={"file": file})
        if response.status_code == 200:
            logging.info(f"Uploaded attachment to Confluence successfully.")
            os.remove(filename)  # Remove the file after uploading
        else:
            logging.error(f"Error uploading attachment to Confluence: {response.text}")

# Function to collect and write data for all replication slots
def collect_replication_slot_data():
    query = "SELECT NOW() AS timestamp, * FROM pg_replication_slots"
    filename = os.path.join(data_directory, "all_replication_slots.csv")
    fetch_and_write_to_csv(query, filename, all_slot_data)

# Function to collect and write data for all pg_stat_replication
def collect_pg_stat_replication_data():
    query = "SELECT NOW() AS timestamp, * FROM pg_stat_replication"
    filename = os.path.join(data_directory, "all_pg_stat_replication.csv")
    fetch_and_write_to_csv(query, filename, all_stat_data)

# Schedule the task to run every 2 minutes
schedule.every(2).minutes.do(collect_replication_slot_data)
schedule.every(2).minutes.do(collect_pg_stat_replication_data)

# Schedule the publishing and cleanup task to run every 24 hours
def publish_and_cleanup():
    # Upload CSV files to Confluence
    post_to_confluence(os.path.join(data_directory, "all_replication_slots.csv"))
    post_to_confluence(os.path.join(data_directory, "all_pg_stat_replication.csv"))

    # Remove old CSV files
    for filename in os.listdir(data_directory):
        file_path = os.path.join(data_directory, filename)
        try:
            if os.path.isfile(file_path):
                os.remove(file_path)
                logging.info(f"Removed old file: {file_path}")
        except Exception as e:
            logging.error(f"Error while removing file: {file_path} - {str(e)}")

# Schedule the publishing and cleanup task to run every 24 hours
schedule.every(24).hours.do(publish_and_cleanup)

# Create the data directory if it doesn't exist
os.makedirs(data_directory, exist_ok=True)

# Run the scheduled tasks
while True:
    schedule.run_pending()
    time.sleep(1)

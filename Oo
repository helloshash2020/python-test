import psycopg2
import concurrent.futures
import logging

# Configure logging
logging.basicConfig(filename='script.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Database connection details
db1_params = {
    'dbname': 'db1',
    'user': 'your_username',
    'password': 'your_password',
    'host': 'db1_host'
}

db2_params = {
    'dbname': 'db2',
    'user': 'your_username',
    'password': 'your_password',
    'host': 'db2_host'
}

# Function to get row count for a table
def get_row_count(schema, table, db_params):
    try:
        connection = psycopg2.connect(**db_params)
        cursor = connection.cursor()
        cursor.execute(f"SELECT COUNT(*) FROM {schema}.{table}")
        count = cursor.fetchone()[0]
        logging.info(f"Processed {schema}.{table}")
        return count
    except Exception as e:
        logging.error(f"Error processing {schema}.{table}: {str(e)}")
        return None
    finally:
        if connection:
            connection.close()

# Retrieve schema and table names from replication_list table in db1
try:
    conn1 = psycopg2.connect(**db1_params)
    cursor = conn1.cursor()
    cursor.execute("SELECT schema_name, table_name FROM replication_list")
    schema_table_list = cursor.fetchall()
    logging.info("Retrieved schema and table names from replication_list")
except Exception as e:
    logging.error(f"Error fetching data from replication_list: {str(e)}")
    conn1.close()
    raise

# Initialize dictionaries to store row counts
db1_row_counts = {}
db2_row_counts = {}
difference_counts = {}

# Use concurrent.futures to fetch row counts concurrently
with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:  # Adjust max_workers as needed
    # Fetch counts for db1
    db1_results = {executor.submit(get_row_count, schema, table, db1_params): (schema, table) for schema, table in schema_table_list}
    # Fetch counts for db2
    db2_results = {executor.submit(get_row_count, schema, table, db2_params): (schema, table) for schema, table in schema_table_list}

    for future in concurrent.futures.as_completed(db1_results):
        schema, table = db1_results[future]
        count = future.result()
        if count is not None:
            db1_row_counts[f"{schema}.{table}"] = count

    for future in concurrent.futures.as_completed(db2_results):
        schema, table = db2_results[future]
        count = future.result()
        if count is not None:
            db2_row_counts[f"{schema}.{table}"] = count

# Calculate the difference
for key in db1_row_counts.keys():
    if key in db2_row_counts:
        difference_counts[key] = db1_row_counts[key] - db2_row_counts[key]

# Save the counts in Loutput1, Routput2, and doutput3
try:
    with open('Loutput1.txt', 'w') as loutput_file:
        loutput_file.write(str(db1_row_counts))

    with open('Routput2.txt', 'w') as routput_file:
        routput_file.write(str(db2_row_counts))

    with open('doutput3.txt', 'w') as doutput_file:
        doutput_file.write(str(difference_counts))

    logging.info("Counts saved successfully")
except Exception as e:
    logging.error(f"Error saving counts: {str(e)}")

# Close database connections
cursor.close()
conn1.close()
